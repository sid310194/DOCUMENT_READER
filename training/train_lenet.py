# -*- coding: utf-8 -*-
"""lenet_accurate.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TJMWjzBLnPkTAx6HVImTMRoVSHMonh_3
"""

import matplotlib.pyplot as plt
import numpy as np
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import torch.optim as optim

#!unzip /content/drive/'My Drive'/dataset_project.zip

transform_train = transforms.Compose([transforms.Grayscale(num_output_channels=1),
    transforms.Resize([64,64]), 
    transforms.ToTensor()
    ])

transform_test = transforms.Compose([transforms.Grayscale(num_output_channels=1),
    transforms.Resize([64,64]), 
    transforms.ToTensor()
    ])

class LeNet(nn.Module):
    def __init__(self): 
        super(LeNet, self).__init__()
        self.cnn_model = nn.Sequential(
            nn.Conv2d(1, 6, 5),         # (N, 1, 64, 64) -> (N,  6, 60, 60)
            nn.ReLU(),
            nn.AvgPool2d(2, stride=2),  # (N, 6, 60, 60) -> (N,  6, 30, 30)
            nn.Conv2d(6, 16, 5),        # (N, 6, 30, 30) -> (N, 16, 26, 26)  
            nn.ReLU(),
            nn.AvgPool2d(2, stride=2)   # (N,16, 26, 26) -> (N, 16, 13, 13)
        )
        self.fc_model = nn.Sequential(
            nn.Linear(2704,1024),         # (N,2704) -> (N,1024)
            nn.ReLU(),
            nn.Linear(1024,256),          # (N,1024) -> (N,256)
            nn.ReLU(),
            nn.Linear(256,62)            # (N, 256)  -> (N, 62)
        )
        
    def forward(self, x):
        x = self.cnn_model(x)
        x = x.view(x.size(0), -1)
        x = self.fc_model(x)
        return x

batch_size = 128
dataset= torchvision.datasets.ImageFolder(root='/content/dataset_project',transform=transform_train)
train_set,test_set = torch.utils.data.random_split(dataset, [44092,18900])
trainloader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)
#testset = torchvision.datasets.ImageFolder(root='/content/testing_project',transform=transform_test)
testloader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)

dataiter = iter(trainloader)
images, labels = dataiter.next()

print(images.shape)

print(images[1].shape)
print(labels[1].item())

import os
os.environ['CUDA_LAUNCH_BLOCKING'] = "1"

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print(device)

def accuracy(dataloader,topk=(1,)):
  for data in dataloader:
    inputs, target = data
    inputs, target = inputs.to(device), target.to(device)
    output= net(inputs)
  maxk = max(topk)
  batch_size = target.size(0)
  _, pred = output.topk(maxk, 1, True, True)
  pred = pred.t()
  correct = pred.eq(target.view(1, -1).expand_as(pred))

  res = []
  for k in topk:
    correct_k = correct[:k].view(-1).float().sum(0)
    res.append(correct_k.mul_(100.0 / batch_size))
  return res

def evaluation(dataloader):
    total, correct = 0, 0
    for data in dataloader:
        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)
        outputs = net(inputs)
        _, pred = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (pred == labels).sum().item()
    return 100 * correct / total

net = LeNet().to(device)
loss_fn = nn.CrossEntropyLoss()
opt = optim.Adam(net.parameters())

import copy

loss_epoch_arr = []
loss_arr = []
max_epochs =50

min_loss = 10



for epoch in range(max_epochs):

    for i, data in enumerate(trainloader, 0):

        inputs, labels = data
        inputs, labels = inputs.to(device), labels.to(device)

        opt.zero_grad()

        outputs = net(inputs)
        loss = loss_fn(outputs, labels)
        loss.backward()
        opt.step()
        
        if min_loss > loss.item():
            min_loss = loss.item()
            loss_arr.append(min_loss)
            best_model = copy.deepcopy(net.state_dict())
            torch.save(best_model,'/content/drive/My Drive/new_model.pt')
            print('Min loss %0.4f' % min_loss)
        
       
            
        del inputs, labels, outputs
        torch.cuda.empty_cache()
        
    loss_epoch_arr.append(loss.item())
    print('Epoch: %d/%d, Test acc: %0.4f, Train acc: %0.4f' % (epoch, max_epochs, evaluation(testloader), evaluation(trainloader)))
plt.plot(loss_epoch_arr)
plt.show()

net.load_state_dict(best_model)
print(evaluation(trainloader), evaluation(testloader))

print(accuracy(trainloader,topk=(2,)), accuracy(testloader,topk=(2,)))

print(accuracy(trainloader,topk=(3,)), accuracy(testloader,topk=(3,)))

print(accuracy(trainloader,topk=(5,)), accuracy(testloader,topk=(5,)))


